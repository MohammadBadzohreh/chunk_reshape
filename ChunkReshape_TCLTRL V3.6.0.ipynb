{"cells":[{"cell_type":"markdown","source":["#Version 3.6.0\n","<hr>\n","Report of forward time spent on MNIST and CIFAR10. Five models for each dataset.\n","\n","1. Base Model\n","2. TRL only Model\n","3. TCL+TRL Model\n","4. ChunkReshape map type 1 + TCL + TRL Model\n","5. ChunkReshape map type 2 + TCL + TRL Model\n","\n","<hr>\n","\n","## Issues:\n","\n","- Study the case of inconsistency in Forward time reports\n","\n","- Reshape time still remains longer\n","\n","## Attempts :\n","\n","- Try to generate and empty output from init\n","\n","- Try to replicate the process using built-in functions\n","\n","The result of these attempts are reported at the last code blocks"],"metadata":{"id":"Kp3FhdQBso0_"}},{"cell_type":"markdown","metadata":{"id":"lRUeJm_OTOdV"},"source":["#Reshape Tensor to a higher dimensional Tensor\n","\n","In this notetbook, we study the case of reshaping a tensor (i.e 3-Tensor) to a \n","higher dimensional tensor (i.e 6-Tensor) and its effect on Tensor Contraction and Regression Layer as previously studied at official Tensorly documentation website.\n","\n","\n","The process is as follow:\n","1. Given a n-dimensional tensor, there are n modes and the first mode (mode-1) is considered to be the mode responsible for handling the batch index.\n","2. There are multiple fibers and the goal is to break them into different chunks and rearrange them in a higher dimensional tensor.\n","3. Breaking the fibers with coefficients such as $l_1$, etc; Whereas each mode $i$ is split into $l_i$ equal length chunks.\n","4. The newly made tensor is of the double dimension of the original tensor, for example if the original tensor is 3-dimensional then the new tensor is 6-dimensional.\n","5. We study to approaches in spliting the modes:\n","  - normal split  :  $[0,\\dots,l_i],[l_i+1,\\dots,2l_i],\\dots$\n","  - down sampling :  Usually for the cases when $l_i$ is 2, odd and even indices. \n","6. According to the types of splits there are 2 mapping functions (3-Tensor):\n","  - map 1 : $B(i_1,i_2,i_3,j_1,j_2,j_3) = A(j_1 + (i_1 - 1)M_1, j_2 + (i_2 - 1)M_2, j_3 + (i_3 - 1)M_3)$\n","  - map 2 : $B(i_1,i_2,i_3,j_1,j_2,j_3) = A(M_1(j_1 - 1) + i_1, M_2(j_2 - 1) + i_2), M_3(j_3 - 1) + i_3$\n","  - Where $M_i$ is $\\frac{I_i}{l_i}$, and $I_i$ is the original size of model $i$.\n","7. We can easily expand the maps to fit n-dimensional tensors as well.\n","\n","\n","For this case we create ChunkReshape class where we can do the just that. "]},{"cell_type":"code","execution_count":133,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8209,"status":"ok","timestamp":1683989399274,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"a7iQS-r3Yz_k","outputId":"7abf7ea0-7ebd-4252-a5b4-78fc8593918a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorly-torch in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorly-torch) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tensorly-torch) (1.10.1)\n","Requirement already satisfied: nose in /usr/local/lib/python3.10/dist-packages (from tensorly-torch) (1.3.7)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorly in /usr/local/lib/python3.10/dist-packages (0.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorly) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tensorly) (1.10.1)\n"]}],"source":["# Necessary Packages \n","!pip install tensorly-torch \n","!pip install tensorly\n","\n","import tltorch # TCL and TRL\n","import tensorly as tl # Tensor operation \n","import torch   #  Neural Network\n","from torch import nn # Neural Network\n","from torch.autograd import Variable # Tensor input\n","import torch.optim as optim # Optimization\n","from torchvision import datasets, transforms # Datasets and transoforms\n","import torchvision # Data Loader\n","import torch.nn.functional as F # Activation Functions\n","\n","import numpy as np # Numerical operations\n","import itertools # Generate indices\n","\n","import matplotlib.pyplot as plt # Generate plots\n","import pandas as pd # Save the result as a sheet\n","\n","import time # execuation time\n","import os # to save the results"]},{"cell_type":"markdown","source":["# Original Chunk Reshape\n","\n","Original as in the first model to be created."],"metadata":{"id":"Y2FNS7AedCzs"}},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":837,"status":"ok","timestamp":1683978958398,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"3ft6MV6fTLgr"},"outputs":[],"source":["class chunkReshape(nn.Module):\n","  \"\"\"Tensor higher dimensional reshape- smaller chunk reshape\n","\n","    Parameters\n","    ----------\n","    input_size : int iterable\n","        shape of the input, excluding batch size\n","    L : int list or int\n","        split coefficients for each mode, excluding batch size\n","    \n","    References\n","    ----------\n","     N/A\n","    \"\"\"\n","\n","  def __init__(self, input_size, L, map_type = 1, device=None, dtype=None):\n","      # Input contains the batch size mode\n","      # L doesnt contain the batch size mode\n","\n","      super().__init__()\n","\n","      if isinstance(input_size, int):\n","        self.input_size = (input_size, )\n","      else:\n","        self.input_size = tuple(input_size)\n","      if isinstance(L, int):\n","        self.L = (L, )\n","      else:\n","        self.L = tuple(L)\n","      if map_type == 1 or self.L.count(2) != len(self.L):\n","          self.map_type = 1\n","      else:\n","          self.map_type = 2\n","\n","      self.device = device\n","      self.dtype  = dtype\n","\n","\n","      # many operations in init\n","\n","      self.M = []\n","      for i,_ in enumerate(self.L):\n","          if self.input_size[i] % self.L[i] != 0:\n","              raise RuntimeError(f'Bad L : input_size {self.input_size[i]} is not divisible by L size {self.L[i]}')\n","          self.M.append(int(self.input_size[i] / self.L[i]))\n","\n","      self.lists_indices = []\n","      for i in range(len((list(self.L) + self.M))):\n","          self.lists_indices.append(np.arange((list(self.L) + self.M)[i]))\n","\n","\n","      self.indices = np.array([p for p in itertools.product(*self.lists_indices)])\n","\n","  def forward(self, x):\n","    \"\"\"Performs a forward pass\"\"\"\n","    \n","    # generate output shape\n","    new_shapes = tuple([x.shape[0]] + list(self.L) + self.M)\n","    out = torch.empty(new_shapes, device=self.device, dtype=self.dtype)\n","\n","    # generate all possible combination of indices\n","\n","    # Already generated in init\n","\n","    # Mapping\n","\n","    if self.map_type == 1:\n","      \n","      for index_B in self.indices:\n","\n","          # Input is : x\n","          # Output is : out\n","          # Maps via exec() command\n","          ### Command to execute\n","          code = '' + 'out[:,'\n","          map_B_string = ','.join(map(str, index_B))\n","          code += map_B_string + ']'\n","          ### Command to execute\n","\n","          index_A = []\n","          for ii in range(len(index_B)):\n","              index_A.append(index_B[ii]*self.M[ii] +  index_B[ii+len(self.L)])\n","              if ii == len(self.L) - 1:\n","                  ### Command to execute\n","                  map_A_string = ','.join(map(str, index_A))\n","                  code += '= x[:,'\n","                  code += map_A_string + ']'\n","                  ### Command to execute\n","                  # If the original dim is 3D then the \n","                  # code is similar to : out[:,0,0,0,0,0,0] = x[:,0,0,0]\n","                  exec(code)\n","                  break  \n","\n","      return out\n","      \n","    else:\n","\n","      for index_B in self.indices:\n","\n","          # Input is : x\n","          # Output is : out\n","          # Maps via exec() command\n","          ### Command to execute\n","          code = '' + 'out[:,'\n","          map_B_string = ','.join(map(str, index_B))\n","          code += map_B_string + ']'\n","          ### Command to execute\n","\n","          index_A = []\n","          for ii in range(len(index_B)):\n","              index_A.append(index_B[ii + len(self.L)]*2 +  index_B[ii])\n","              if ii == len(self.L) - 1:\n","                  ### Command to execute\n","                  map_A_string = ','.join(map(str, index_A))\n","                  code += '= x[:,'\n","                  code += map_A_string + ']'\n","                  ### Command to execute\n","                  # If the original dim is 3D then the \n","                  # code is similar to : out[:,0,0,0,0,0,0] = x[:,0,0,0]\n","                  exec(code)\n","                  break  \n","      return out\n"]},{"cell_type":"markdown","source":["# Version  2 of chunk reshape\n","\n","Another version of chunk reshape to study the case of creating output from the init and then calculating the time spent."],"metadata":{"id":"BuBPtXZn97kA"}},{"cell_type":"code","source":["class chunkReshape_version2(nn.Module):\n","  \"\"\"Tensor higher dimensional reshape- smaller chunk reshape\n","\n","    Parameters\n","    ----------\n","    input_size : int iterable\n","        shape of the input, excluding batch size\n","    L : int list or int\n","        split coefficients for each mode, excluding batch size\n","    \n","    References\n","    ----------\n","     N/A\n","    \"\"\"\n","\n","  def __init__(self, input_size, L, batch_size, map_type = 1, device=None, dtype=None):\n","      # Input contains the batch size mode\n","      # L doesnt contain the batch size mode\n","\n","      super().__init__()\n","\n","      if isinstance(input_size, int):\n","        self.input_size = (input_size, )\n","      else:\n","        self.input_size = tuple(input_size)\n","      if isinstance(L, int):\n","        self.L = (L, )\n","      else:\n","        self.L = tuple(L)\n","      if map_type == 1 or self.L.count(2) != len(self.L):\n","          self.map_type = 1\n","      else:\n","          self.map_type = 2\n","\n","      self.device = device\n","      self.dtype  = dtype\n","      self.batch_size = batch_size\n","\n","\n","      # many operations in init\n","\n","      self.M = []\n","      for i,_ in enumerate(self.L):\n","          if self.input_size[i] % self.L[i] != 0:\n","              raise RuntimeError(f'Bad L : input_size {self.input_size[i]} is not divisible by L size {self.L[i]}')\n","          self.M.append(int(self.input_size[i] / self.L[i]))\n","\n","      self.lists_indices = []\n","      for i in range(len((list(self.L) + self.M))):\n","          self.lists_indices.append(np.arange((list(self.L) + self.M)[i]))\n","\n","\n","      self.indices = np.array([p for p in itertools.product(*self.lists_indices)])\n","\n","      self.new_shapes = tuple([self.batch_size] + list(self.L) + self.M)\n","\n","      self.out = torch.empty(self.new_shapes, device=self.device, dtype=self.dtype)\n","      \n","\n","  def forward(self, x):\n","    \"\"\"Performs a forward pass\"\"\"\n","    \n","    # generate output shape\n","    \n","    # Already generated in init\n","\n","    # generate all possible combination of indices\n","\n","    # Already generated in init\n","\n","    # Mapping\n","\n","    if self.map_type == 1:\n","      \n","      for index_B in self.indices:\n","\n","          # Input is : x\n","          # Output is : out\n","          # Maps via exec() command\n","          ### Command to execute\n","          code = '' + 'self.out[:,'\n","          map_B_string = ','.join(map(str, index_B))\n","          code += map_B_string + ']'\n","          ### Command to execute\n","\n","          index_A = []\n","          for ii in range(len(index_B)):\n","              index_A.append(index_B[ii]*self.M[ii] +  index_B[ii+len(self.L)])\n","              if ii == len(self.L) - 1:\n","                  ### Command to execute\n","                  map_A_string = ','.join(map(str, index_A))\n","                  code += '= x[:,'\n","                  code += map_A_string + ']'\n","                  ### Command to execute\n","                  # If the original dim is 3D then the \n","                  # code is similar to : out[:,0,0,0,0,0,0] = x[:,0,0,0]\n","                  exec(code)\n","                  break  \n","\n","      return self.out\n","      \n","    else:\n","\n","      for index_B in self.indices:\n","\n","          # Input is : x\n","          # Output is : out\n","          # Maps via exec() command\n","          ### Command to execute\n","          code = '' + 'self.out[:,'\n","          map_B_string = ','.join(map(str, index_B))\n","          code += map_B_string + ']'\n","          ### Command to execute\n","\n","          index_A = []\n","          for ii in range(len(index_B)):\n","              index_A.append(index_B[ii + len(self.L)]*2 +  index_B[ii])\n","              if ii == len(self.L) - 1:\n","                  ### Command to execute\n","                  map_A_string = ','.join(map(str, index_A))\n","                  code += '= x[:,'\n","                  code += map_A_string + ']'\n","                  ### Command to execute\n","                  # If the original dim is 3D then the \n","                  # code is similar to : out[:,0,0,0,0,0,0] = x[:,0,0,0]\n","                  exec(code)\n","                  break  \n","      return self.out\n"],"metadata":{"id":"cHhz-ngs-LQq","executionInfo":{"status":"ok","timestamp":1683980305456,"user_tz":-210,"elapsed":6,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["# Version 3 of chunk reshape"],"metadata":{"id":"zNUagJIaa1xj"}},{"cell_type":"code","source":["class chunkReshape_version3(nn.Module):\n","  \"\"\"Tensor higher dimensional reshape- smaller chunk reshape\n","\n","    Parameters\n","    ----------\n","    input_size : int iterable\n","        shape of the input, excluding batch size\n","    L : int list or int\n","        split coefficients for each mode, excluding batch size\n","    \n","    References\n","    ----------\n","     N/A\n","    \"\"\"\n","\n","  def __init__(self, input_size, L, batch_size, map_type = 1, device=None, dtype=None):\n","      # Input contains the batch size mode\n","      # L doesnt contain the batch size mode\n","\n","      super().__init__()\n","\n","      if isinstance(input_size, int):\n","        self.input_size = (input_size, )\n","      else:\n","        self.input_size = tuple(input_size)\n","      if isinstance(L, int):\n","        self.L = (L, )\n","      else:\n","        self.L = tuple(L)\n","      if map_type == 1 or self.L.count(2) != len(self.L):\n","          self.map_type = 1\n","      else:\n","          self.map_type = 2\n","\n","      self.device = device\n","      self.dtype  = dtype\n","      self.batch_size = batch_size\n","\n","\n","      # many operations in init\n","\n","      self.M = []\n","      for i,_ in enumerate(self.L):\n","          if self.input_size[i] % self.L[i] != 0:\n","              raise RuntimeError(f'Bad L : input_size {self.input_size[i]} is not divisible by L size {self.L[i]}')\n","          self.M.append(int(self.input_size[i] / self.L[i]))\n","\n","      self.lists_indices = []\n","      for i in range(len((list(self.L) + self.M))):\n","          self.lists_indices.append(np.arange((list(self.L) + self.M)[i]))\n","\n","\n","      self.indices = np.array([p for p in itertools.product(*self.lists_indices)])\n","\n","      self.new_shapes = tuple([self.batch_size] + list(self.L) + self.M)\n","\n","      #self.out = torch.empty(self.new_shapes, device=self.device, dtype=self.dtype)\n","      \n","\n","  def forward(self, x):\n","    \"\"\"Performs a forward pass\"\"\"\n","    \n","    # generate output shape\n","    \n","    out = x.reshape(self.new_shapes)\n","\n","    # generate all possible combination of indices\n","\n","    # Already generated in init\n","\n","    # Mapping\n","\n","    if self.map_type == 1:\n","      \n","      for index_B in self.indices:\n","\n","          # Input is : x\n","          # Output is : out\n","          # Maps via exec() command\n","          ### Command to execute\n","          code = '' + 'out[:,'\n","          map_B_string = ','.join(map(str, index_B))\n","          code += map_B_string + ']'\n","          ### Command to execute\n","\n","          index_A = []\n","          for ii in range(len(index_B)):\n","              index_A.append(index_B[ii]*self.M[ii] +  index_B[ii+len(self.L)])\n","              if ii == len(self.L) - 1:\n","                  ### Command to execute\n","                  map_A_string = ','.join(map(str, index_A))\n","                  code += '= x[:,'\n","                  code += map_A_string + ']'\n","                  ### Command to execute\n","                  # If the original dim is 3D then the \n","                  # code is similar to : out[:,0,0,0,0,0,0] = x[:,0,0,0]\n","                  exec(code)\n","                  break  \n","\n","      return out\n","      \n","    else:\n","\n","      for index_B in self.indices:\n","\n","          # Input is : x\n","          # Output is : out\n","          # Maps via exec() command\n","          ### Command to execute\n","          code = '' + 'out[:,'\n","          map_B_string = ','.join(map(str, index_B))\n","          code += map_B_string + ']'\n","          ### Command to execute\n","\n","          index_A = []\n","          for ii in range(len(index_B)):\n","              index_A.append(index_B[ii + len(self.L)]*2 +  index_B[ii])\n","              if ii == len(self.L) - 1:\n","                  ### Command to execute\n","                  map_A_string = ','.join(map(str, index_A))\n","                  code += '= x[:,'\n","                  code += map_A_string + ']'\n","                  ### Command to execute\n","                  # If the original dim is 3D then the \n","                  # code is similar to : out[:,0,0,0,0,0,0] = x[:,0,0,0]\n","                  exec(code)\n","                  break  \n","      return out\n"],"metadata":{"id":"fm0H_p8xa3-9","executionInfo":{"status":"ok","timestamp":1683987160971,"user_tz":-210,"elapsed":2,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"execution_count":130,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gB55xpU8LJzQ"},"source":["# MNIST Dataset\n","\n","- A Large batch size is required to notice the difference between models in <code> forward() </code>\n","\n","- Defined as function to generalize in <b> Report Section </b>\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1235,"status":"ok","timestamp":1683979186715,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"XERYYb1gLJLi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ebe15a2-5626-4143-cd61-f449353b94bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 203423579.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 27637621.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 68121424.67it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 4542/4542 [00:00<00:00, 15388149.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(200,\n"," 'cuda',\n"," <torch.utils.data.dataloader.DataLoader at 0x7f1c1c7ea1a0>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7f1c1c7eb640>)"]},"metadata":{},"execution_count":5}],"source":["# Big Batch_size to notice the difference\n","\n","# Defined as a function to generalize in Report Section\n","\n","# to run on CPU, uncomment the following line:\n","#device = 'cpu'\n","\n","MNIST_train_dataset = datasets.MNIST('./data/', train=True, download=True,\n","                        transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                        ])) \n","MNIST_test_dataset = datasets.MNIST('./data/', train=False, download=True,\n","                        transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                        ]))\n","\n","\n","def MNIST_loader(_batch_size = 200 ,_device = 'cuda'):\n","\n","    batch_size = _batch_size\n","    device = _device   \n","\n","    train_loader_mnist = torch.utils.data.DataLoader(MNIST_train_dataset,\n","          batch_size=batch_size, shuffle=True)\n","    test_loader_mnist = torch.utils.data.DataLoader(MNIST_test_dataset,\n","          batch_size=batch_size, shuffle=True)\n","    \n","    return batch_size, device, train_loader_mnist, test_loader_mnist\n","\n","\n","# Initialize \n","MNIST_loader()"]},{"cell_type":"markdown","source":["## Example of Chunk Reshape of a Tensor - MNIST"],"metadata":{"id":"LmO9rDmH6P9G"}},{"cell_type":"code","source":["# Dataset Loaders\n","batch_size, device, train_loader_mnist, test_loader_mnist = MNIST_loader()\n","\n","\n","# Get a batch from dataset\n","examples_mnist = enumerate(train_loader_mnist)\n","batch_idx, (example_data_mnist, example_targets_mnist) = next(examples_mnist)\n","\n","\n","# One forward through Net\n","print('Input shape ', example_data_mnist.shape)\n","conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","x1 = F.relu(F.max_pool2d(conv1(example_data_mnist), 2))\n","print('Input shape after convolution kernel 5 and max pooling kernel 2 ', x1.shape)\n","conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","x2 = F.relu(F.max_pool2d(conv2(x1), 2))\n","print('Input shape after another convolution kernel 5 and max pooling kernel 2 ', x2.shape)\n","print('Ready for Reshape Using L = [2,2,2] and map type 1')\n","# With Reshape\n","Chunk_Reshape = chunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 1)\n","x3 = Chunk_Reshape(x2)\n","print('output size of Chunk Reshape', x3.shape)\n","# TCL \n","tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","x4 = F.relu(tcl(x3))\n","print('output size of TCL', x4.shape)\n","x5 = x4.squeeze()\n","print('output size of TCL with squeeze() ', x5.shape)\n","# TRL \n","trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","x6 = trl(x5)\n","print('output size of TRL', x6.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKkxf1HM6TZT","outputId":"bb23c967-302b-4684-8898-968dfd188a83","executionInfo":{"status":"ok","timestamp":1683979336069,"user_tz":-210,"elapsed":518,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape  torch.Size([200, 1, 28, 28])\n","Input shape after convolution kernel 5 and max pooling kernel 2  torch.Size([200, 20, 12, 12])\n","Input shape after another convolution kernel 5 and max pooling kernel 2  torch.Size([200, 50, 4, 4])\n","Ready for Reshape Using L = [2,2,2] and map type 1\n","output size of Chunk Reshape torch.Size([200, 2, 2, 2, 25, 2, 2])\n","output size of TCL torch.Size([200, 1, 1, 1, 13, 2, 2])\n","output size of TCL with squeeze()  torch.Size([200, 13, 2, 2])\n","output size of TRL torch.Size([200, 10])\n"]}]},{"cell_type":"markdown","source":["# CIFAR10 Dataset\n","\n","- Same Batch size same Issues as MNIST"],"metadata":{"id":"DtQ8p0zwaep7"}},{"cell_type":"code","source":["# Big Batch_size to notice the difference\n","\n","# Defined as a function to generalize in Report Section\n","\n","# to run on CPU, uncomment the following line:\n","#device = 'cpu'\n","\n","CIFAR10_train_dataset = datasets.CIFAR10('./data/', train=True, download=True,\n","                        transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n","                        ])) \n","CIFAR10_test_dataset = datasets.CIFAR10('./data/', train=False, download=True,\n","                        transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n","                        ]))\n","\n","\n","\n","def CIFAR10_loader(_batch_size = 200 ,_device = 'cuda'):\n","\n","    batch_size = _batch_size\n","    device = _device   \n","\n","    train_loader_cifar10 = torch.utils.data.DataLoader(CIFAR10_train_dataset,\n","          batch_size=batch_size, shuffle=True)\n","    test_loader_cifar10 = torch.utils.data.DataLoader(CIFAR10_test_dataset,\n","          batch_size=batch_size, shuffle=True)\n","    \n","    return batch_size, device, train_loader_cifar10, test_loader_cifar10\n","\n","\n","# Initialize \n","CIFAR10_classes = ['plane', 'car', 'bird', 'cat',\n","                  'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","CIFAR10_loader()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_MFjvNmtgP4","executionInfo":{"status":"ok","timestamp":1683979350743,"user_tz":-210,"elapsed":9743,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"d52ee4b5-2dae-4c50-b81c-ab6179288e76"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:05<00:00, 29597536.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data/\n","Files already downloaded and verified\n"]},{"output_type":"execute_result","data":{"text/plain":["(200,\n"," 'cuda',\n"," <torch.utils.data.dataloader.DataLoader at 0x7f1c28d0dff0>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7f1c1c85a9e0>)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Example of Chunk Reshape of a Tensor - CIFAR10"],"metadata":{"id":"MZVyCtN6b_RH"}},{"cell_type":"code","source":["# Dataset Loaders\n","batch_size, device, train_loader_cifar10, test_loader_cifar10 = CIFAR10_loader()\n","\n","# Get a batch from dataset\n","examples_cifar10 = enumerate(train_loader_cifar10)\n","batch_idx, (example_data_cifar10, example_targets_cifar10) = next(examples_cifar10)\n","\n","print('Input shape ', example_data_cifar10.shape)\n","conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","x1 = F.relu(F.max_pool2d(conv1(example_data_cifar10), 2))\n","print('Input shape after convolution kernel 5 and max pooling kernel 2 ', x1.shape)\n","conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","x2 = F.relu(F.max_pool2d(conv2(x1), 2))\n","print('Input shape after another convolution kernel 6 and max pooling kernel 2 ', x2.shape)\n","print('Ready for Reshape Using L = [2,2,2] and map type 1')\n","# With Reshape\n","Chunk_Reshape = chunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 1)\n","x3 = Chunk_Reshape(x2)\n","print('output size of Chunk Reshape', x3.shape)\n","# TCL \n","tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","x4 = F.relu(tcl(x3))\n","print('output size of TCL', x4.shape)\n","x5 = x4.squeeze()\n","print('output size of TCL with squeeze() ', x5.shape)\n","# TRL \n","trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","x6 = trl(x5)\n","print('output size of TRL', x6.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a3pq7ACcAvs","executionInfo":{"status":"ok","timestamp":1683979358949,"user_tz":-210,"elapsed":562,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"1fa6d7e3-da96-4785-a0ab-31cff153bdc5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape  torch.Size([200, 3, 32, 32])\n","Input shape after convolution kernel 5 and max pooling kernel 2  torch.Size([200, 20, 14, 14])\n","Input shape after another convolution kernel 6 and max pooling kernel 2  torch.Size([200, 50, 4, 4])\n","Ready for Reshape Using L = [2,2,2] and map type 1\n","output size of Chunk Reshape torch.Size([200, 2, 2, 2, 25, 2, 2])\n","output size of TCL torch.Size([200, 1, 1, 1, 13, 2, 2])\n","output size of TCL with squeeze()  torch.Size([200, 13, 2, 2])\n","output size of TRL torch.Size([200, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"8Ty910HUSR_x"},"source":["# Create Networks"]},{"cell_type":"markdown","source":["## MNIST Models\n","\n","- Base Model\n","- TRL only Model\n","- TCL + TRL Model\n","- Chunk Reshape map type 1 + TCL + TRL Model\n","- Chunk Reshape map type 2 + TCL + TRL Model"],"metadata":{"id":"HDvm9KSq8IM6"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"al9yqDufR5cL","executionInfo":{"status":"ok","timestamp":1683979655364,"user_tz":-210,"elapsed":4,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"outputs":[],"source":["\n","# Base Model\n","\n","class MNIST_Net_base(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_base, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(800, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1,800)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# TRL only Model\n","\n","class MNIST_Net_TRL(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_TRL, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.trl = tltorch.TRL(input_shape = [50,4,4] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# TCL + TRL Model\n","\n","class MNIST_Net_TCL_TRL(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_TCL_TRL, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.tcl = tltorch.TCL(input_shape= [50,4,4], rank=[30,2,2])\n","        self.trl = tltorch.TRL(input_shape = [30,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = F.relu(self.tcl(x))\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","# Chunk Reshape map type 1 + TCL + TRL Model\n","\n","class MNIST_Net_chunk_TCL_TRL_map1(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_chunk_TCL_TRL_map1, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.chunk = chunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 1, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","\n","# Chunk Reshape map type 2 + TCL + TRL Model\n","\n","class MNIST_Net_chunk_TCL_TRL_map2(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_chunk_TCL_TRL_map2, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.chunk = chunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 2, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# Chunk Reshape map type 1 + TCL + TRL Model version 2 of chunk reshape\n","\n","class MNIST_Net_chunk_TCL_TRL_map1_version2(nn.Module):\n","    def __init__(self, _batch_size):\n","        super(MNIST_Net_chunk_TCL_TRL_map1_version2, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.chunk = chunkReshape_version2(input_size = [50,4,4], L = [2,2,2], batch_size= _batch_size , map_type = 1, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","\n","# Chunk Reshape map type 2 + TCL + TRL Model version 2 of chunk reshape\n","\n","class MNIST_Net_chunk_TCL_TRL_map2_version2(nn.Module):\n","    def __init__(self, _batch_size):\n","        super(MNIST_Net_chunk_TCL_TRL_map2_version2, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.chunk = chunkReshape_version2(input_size = [50,4,4], L = [2,2,2], batch_size = _batch_size, map_type = 2, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n"]},{"cell_type":"markdown","source":["## CIFAR10 Models\n","\n","- Base Model\n","- TRL only Model\n","- TCL + TRL Model\n","- Chunk Reshape map type 1 + TCL + TRL Model\n","- Chunk Reshape map type 2 + TCL + TRL Model"],"metadata":{"id":"m8pmzLwad6AC"}},{"cell_type":"code","source":["\n","# Base Model\n","\n","class CIFAR10_Net_base(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_base, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(800, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1,800)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# TRL only Model\n","\n","class CIFAR10_Net_TRL(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_TRL, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.trl = tltorch.TRL(input_shape = [50,4,4] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# TCL + TRL Model\n","\n","class CIFAR10_Net_TCL_TRL(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_TCL_TRL, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.tcl = tltorch.TCL(input_shape= [50,4,4], rank=[30,2,2])\n","        self.trl = tltorch.TRL(input_shape = [30,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = F.relu(self.tcl(x))\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","# Chunk Reshape map type 1 + TCL + TRL Model\n","\n","class CIFAR10_Net_chunk_TCL_TRL_map1(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_chunk_TCL_TRL_map1, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.chunk = chunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 1, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","\n","# Chunk Reshape map type 2 + TCL + TRL Model\n","\n","class CIFAR10_Net_chunk_TCL_TRL_map2(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_chunk_TCL_TRL_map2, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.chunk = chunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 2, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# Chunk Reshape map type 1 + TCL + TRL Model version 2 of chunk reshape\n","\n","class CIFAR10_Net_chunk_TCL_TRL_map1_version2(nn.Module):\n","    def __init__(self, _batch_size):\n","        super(CIFAR10_Net_chunk_TCL_TRL_map1_version2, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.chunk = chunkReshape_version2(input_size = [50,4,4], L = [2,2,2], batch_size = _batch_size, map_type = 1, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","\n","# Chunk Reshape map type 2 + TCL + TRL Model version 2 of chunk reshape\n","\n","class CIFAR10_Net_chunk_TCL_TRL_map2_version2(nn.Module):\n","    def __init__(self, _batch_size):\n","        super(CIFAR10_Net_chunk_TCL_TRL_map2_version2, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.chunk = chunkReshape_version2(input_size = [50,4,4], L = [2,2,2], batch_size = _batch_size, map_type = 2, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)"],"metadata":{"id":"KxK_CL9nekgo","executionInfo":{"status":"ok","timestamp":1683979688994,"user_tz":-210,"elapsed":515,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CvcEY6IiVHOT"},"source":["# Models, Optimizers ,and Criterions"]},{"cell_type":"code","source":["# MNIST \n","\n","\n","MNIST_Models = [\n","    MNIST_Net_base(),\n","    MNIST_Net_TRL(),\n","    MNIST_Net_TCL_TRL(),\n","    MNIST_Net_chunk_TCL_TRL_map1(),\n","    MNIST_Net_chunk_TCL_TRL_map2(), \n","]\n","\n","\n","MNIST_Optimizers = [\n","    optim.SGD(MNIST_Models[0].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(MNIST_Models[1].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(MNIST_Models[2].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(MNIST_Models[3].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(MNIST_Models[4].parameters(), lr=0.01, momentum=0.9)\n","]\n","\n","MNIST_Criterion = [\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss()\n","]\n","\n","\n","# CIFAR10\n","\n","CIFAR10_Models= [\n","    CIFAR10_Net_base(),\n","    CIFAR10_Net_TRL(),\n","    CIFAR10_Net_TCL_TRL(),\n","    CIFAR10_Net_chunk_TCL_TRL_map1(),\n","    CIFAR10_Net_chunk_TCL_TRL_map2()\n","]\n","\n","CIFAR10_Optimizers = [\n","    optim.SGD(CIFAR10_Models[0].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(CIFAR10_Models[1].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(CIFAR10_Models[2].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(CIFAR10_Models[3].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(CIFAR10_Models[4].parameters(), lr=0.01, momentum=0.9)\n","]\n","\n","CIFAR10_Criterion = [\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss()\n","]\n","\n"],"metadata":{"id":"Z7cp4a1cfjgk","executionInfo":{"status":"ok","timestamp":1683979766568,"user_tz":-210,"elapsed":494,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Check The Results for one Forward pass on MNIST and CIFAR10"],"metadata":{"id":"A93XlVjHhtJ-"}},{"cell_type":"code","source":["models_names = ['base', 'TRL only', 'TCL + TRL', 'Chunk Reshape map 1 + TCL + TRL', 'Chunk Reshape map 2 + TCL + TRL']"],"metadata":{"id":"8bzUPZhGiBIl","executionInfo":{"status":"ok","timestamp":1683979771388,"user_tz":-210,"elapsed":601,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## MNIST (Report on a single batch forward operation)"],"metadata":{"id":"pARWssTGh6m3"}},{"cell_type":"code","source":["# MNIST\n","\n","for index,_model in enumerate(MNIST_Models):\n","    model = _model.to(device)\n","    st = time.time()\n","    output = model(example_data_mnist.to(device)).to(device)\n","    elapsed_time = time.time() - st\n","    #time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n","    print(f'#### Execution time one forward pass on batch size ({batch_size}) MNIST Dataset is {elapsed_time} Model Type : {models_names[index]}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uC03n9u0hzSp","executionInfo":{"status":"ok","timestamp":1683979774787,"user_tz":-210,"elapsed":1551,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"d918c21a-695d-43e8-c623-f0a87340f899"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["#### Execution time one forward pass on batch size (200) MNIST Dataset is 0.9950940608978271 Model Type : base\n","#### Execution time one forward pass on batch size (200) MNIST Dataset is 0.03965401649475098 Model Type : TRL only\n","#### Execution time one forward pass on batch size (200) MNIST Dataset is 0.0020074844360351562 Model Type : TCL + TRL\n","#### Execution time one forward pass on batch size (200) MNIST Dataset is 0.13838911056518555 Model Type : Chunk Reshape map 1 + TCL + TRL\n","#### Execution time one forward pass on batch size (200) MNIST Dataset is 0.0968160629272461 Model Type : Chunk Reshape map 2 + TCL + TRL\n"]}]},{"cell_type":"markdown","source":["## CIFAR10  (Report on a single batch forward operation)"],"metadata":{"id":"n399dFLxkFsn"}},{"cell_type":"code","source":["# CIFAR10\n","\n","for index,_model in enumerate(CIFAR10_Models):\n","    model = _model.to(device)\n","    st = time.time()\n","    output = model(example_data_cifar10.to(device)).to(device)\n","    elapsed_time = time.time() - st\n","    # time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n","    print(f'#### Execution time one forward pass on batch size ({batch_size}) CIFAR10 Dataset is {elapsed_time} Model Type : {models_names[index]}')\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OfTBsCRkCui","executionInfo":{"status":"ok","timestamp":1683979784671,"user_tz":-210,"elapsed":564,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"7e5e4c5b-a1c4-4f65-dec0-afc689f5c93c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["#### Execution time one forward pass on batch size (200) CIFAR10 Dataset is 0.017882108688354492 Model Type : base\n","#### Execution time one forward pass on batch size (200) CIFAR10 Dataset is 0.0016760826110839844 Model Type : TRL only\n","#### Execution time one forward pass on batch size (200) CIFAR10 Dataset is 0.001870870590209961 Model Type : TCL + TRL\n","#### Execution time one forward pass on batch size (200) CIFAR10 Dataset is 0.08877682685852051 Model Type : Chunk Reshape map 1 + TCL + TRL\n","#### Execution time one forward pass on batch size (200) CIFAR10 Dataset is 0.08987975120544434 Model Type : Chunk Reshape map 2 + TCL + TRL\n"]}]},{"cell_type":"markdown","source":["# Report Section\n","\n","In this section we report different forward passes on different batch sizes and different instances in a csv sheet."],"metadata":{"id":"A7xE9gL1xdhE"}},{"cell_type":"code","source":["# PATH\n","DIRECTORY = './Report'\n","PATH = DIRECTORY + '/reportV3.5.0.csv'\n","if not os.path.exists(DIRECTORY):\n","   os.mkdir(DIRECTORY)\n","\n","# Dataframe\n","columns = [\n","    'Dataset',\n","    'batch_size',\n","    'model',\n","    'forward pass time'\n","]\n","\n","dataframe = pd.DataFrame(columns = columns )\n","\n","datasets = ['MNIST', 'CIFAR10']\n","batch_sizes = [16, 200, 1000, 20000, 60000]\n","# models_names = ['base', 'TRL only', 'TCL + TRL', 'Chunk Reshape map 1 + TCL + TRL', 'Chunk Reshape map 2 + TCL + TRL']\n","\n","for dataset in datasets:\n","    # Get the dataset\n","    for i, model_name in enumerate(models_names):\n","        # Get model and its name\n","        for b in batch_sizes:\n","            # Set a batch size\n","            if dataset == 'MNIST':\n","                # Dataset loaders and models\n","                batch_size, device, train_loader, test_loader = MNIST_loader(_batch_size = b, _device = 'cuda')\n","                model = MNIST_Models[i].to(device)\n","            else:\n","                # Dataset loaders and models\n","                batch_size, device, train_loader, test_loader = CIFAR10_loader(_batch_size = b, _device = 'cuda')\n","                model = CIFAR10_Models[i].to(device)\n","            \n","            # Get one batch of dataset\n","            examples = enumerate(train_loader)\n","            batch_idx, (example_data, example_targets) = next(examples)\n","\n","            # Calculate time spent on forward pass\n","            st = time.time()\n","            output = model(example_data.to(device)).to(device)\n","            elapsed_time = time.time() - st\n","\n","\n","            # dataframe entry\n","            entry = {\n","                columns[0]: [dataset],\n","                columns[1]: [batch_size],\n","                columns[2]: [model_name],\n","                columns[3]: [elapsed_time]\n","            }\n","            # append to dataframe\n","            dataframe = pd.concat([dataframe, pd.DataFrame(entry)], ignore_index = True )\n","            dataframe.reset_index()\n","\n","    #break # To only display MNIST results \n","\n","# Save to file\n","dataframe.to_csv(PATH)\n","# show dataframe\n","display(dataframe)"],"metadata":{"id":"oCfEBWPQxq31"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Study The case of inconsistency in forward time\n","\n","- Possible Cause : Not Optimal implementation of TCL or/and TRL in tensorly-torch package (status : <font color ='red' > Rejected</font> ) \n","\n","- Possible Cause :  Not Optimal Implementation or Reshape forward function (status : <font color = 'yellow'> Pending</font>)\n","  - Itertools\n","  - exec()\n","\n","- Built-in reshape function is much faster and performs as expected but the map it provides is wrong. Overall it is faster than original 3d TCL but with a wrong mapping.\n","\n","- Version 2 of chunk reshape (status : <font color = 'red'> Rejected </font>) \n","  - It is faster but not as fast as built-in reshape function and overall still takes longer to run than original 3d TCL.\n","\n","- Version 3 of chunk reshape (status : <font color = 'red'> Rejected </font>)\n","  - It is still faster than version 2 or the original as it generate the output from the reshaped version of input but it still takes longer to run than built-in reshape function"],"metadata":{"id":"LX40O15XHuCL"}},{"cell_type":"code","source":["tempstring = \"\\n######################################\\n\\n\"\n","\n","# Dataset Loaders\n","batch_size, device, train_loader_mnist, test_loader_mnist = MNIST_loader(_batch_size = 15000, _device = 'cuda')\n","\n","\n","# Get a batch from dataset\n","examples_mnist = enumerate(train_loader_mnist)\n","batch_idx, (example_data_mnist, example_targets_mnist) = next(examples_mnist)\n","\n","\n","# One forward through Net\n","conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","st = time.time()\n","x1 = F.relu(F.max_pool2d(conv1(example_data_mnist), 2))\n","elapsed_time = time.time() - st\n","print('Time spent on first convolution Layer ', elapsed_time)\n","\n","\n","conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","st = time.time()\n","x2 = F.relu(F.max_pool2d(conv2(x1), 2))\n","elapsed_time = time.time() - st\n","print('Time spent on second convolution Layer ', elapsed_time)\n","\n","print(tempstring)\n","# For further studies (and for further simplification for viewers)\n","x2_3d = x2\n","x2_reshape = x2\n","x2_version2 = x2\n","x2_version3 = x2\n","\n","\n","# With Reshape\n","Chunk_Reshape = chunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 1)\n","st = time.time()\n","x3 = Chunk_Reshape(x2)\n","elapsed_time = time.time() - st\n","print('Time spent on Reshaping the Tensor ', elapsed_time)\n","\n","\n","# TCL \n","tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","st_1 = time.time()\n","x4 = F.relu(tcl(x3))\n","elapsed_time_1 = time.time() - st_1\n","print('Time spent on TCL 6 Dimensional ', elapsed_time_1)\n","\n","st_2 = time.time()\n","x5 = x4.squeeze()\n","elapsed_time_2 = time.time() - st_2\n","print('Time spent on squeeze() ', elapsed_time_2)\n","\n","elapsed_time = time.time() - st_1\n","print('Total Time spent TCL 6 dimensional and squeeze() ', elapsed_time)\n","\n","\n","# Total time spent on Reshape + TCL + squeeze()\n","elapsed_time = time.time() - st\n","print('Total Time spent on Reshape + TCL 6 dimensional +  squeeze() ', elapsed_time)\n","\n","print(tempstring)\n","# Case of TCL with 3 dimension\n","\n","tcl_3d = tltorch.TCL(input_shape= [50,4,4], rank=[30,2,2])\n","st = time.time()\n","x4_3d = F.relu(tcl_3d(x2_3d))\n","elapsed_time = time.time() - st\n","print('Time spent on TCL 3 Dimensional ', elapsed_time)\n","\n","print(tempstring)\n","# In case of using reshape in-built function of Tensorly or torch\n","# The result is Not correct but we wish to calculate the time spent\n","st = time.time()\n","x3_reshape = x2_reshape.reshape((batch_size, 2, 2, 2, 25, 2, 2))\n","elapsed_time_1 = time.time() - st\n","print('Reshape time using Tensoly Reshape function : ', elapsed_time_1)\n","st_1 = time.time()\n","x4_reshape = F.relu(tcl(x3_reshape))\n","elapsed_time_2 = time.time() - st_1\n","print('Time spent on TCL 6 Dimensional ', elapsed_time_2)\n","st_2 = time.time()\n","x5_reshape = x4_reshape.squeeze()\n","elapsed_time_3 = time.time() - st_2\n","print('Total Time spent squeeze() ', elapsed_time_3)\n","elapsed_time = time.time() - st\n","print('Total Time spent on Reshape + TCL 6 dimensional +  squeeze() with .reshape function ', elapsed_time)\n","\n","print(tempstring)\n","# In case we are using version 2 of chunk reshape\n","# With Reshape version2\n","Chunk_Reshape = chunkReshape_version2(input_size = [50,4,4], L = [2,2,2], batch_size = batch_size, map_type = 1)\n","st = time.time()\n","x3_version2 = Chunk_Reshape(x2_version2)\n","elapsed_time = time.time() - st\n","print('Time spent on Reshaping the Tensor (version2) ', elapsed_time)\n","\n","\n","# TCL \n","tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","st_1 = time.time()\n","x4_version2 = F.relu(tcl(x3_version2))\n","elapsed_time_1 = time.time() - st_1\n","print('Time spent on TCL 6 Dimensional (version2) ', elapsed_time_1)\n","\n","st_2 = time.time()\n","x5_version2 = x4_version2.squeeze()\n","elapsed_time_2 = time.time() - st_2\n","print('Time spent on squeeze() (version2) ', elapsed_time_2)\n","\n","elapsed_time = time.time() - st_1\n","print('Total Time spent TCL 6 dimensional and squeeze() (version2) ', elapsed_time)\n","\n","\n","# Total time spent on Reshape + TCL + squeeze()\n","elapsed_time = time.time() - st\n","print('Total Time spent on Reshape + TCL 6 dimensional +  squeeze() (version 2) ', elapsed_time)\n","\n","print(tempstring)\n","# In case we are using version 3 of chunk reshape\n","# With Reshape version2\n","Chunk_Reshape = chunkReshape_version3(input_size = [50,4,4], L = [2,2,2], batch_size = batch_size, map_type = 1)\n","st = time.time()\n","x3_version3 = Chunk_Reshape(x2_version3)\n","elapsed_time = time.time() - st\n","print('Time spent on Reshaping the Tensor (version3) ', elapsed_time)\n","\n","\n","# TCL \n","tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","st_1 = time.time()\n","x4_version3 = F.relu(tcl(x3_version3))\n","elapsed_time_1 = time.time() - st_1\n","print('Time spent on TCL 6 Dimensional (version3) ', elapsed_time_1)\n","\n","st_2 = time.time()\n","x5_version3 = x4_version3.squeeze()\n","elapsed_time_2 = time.time() - st_2\n","print('Time spent on squeeze() (version3) ', elapsed_time_2)\n","\n","elapsed_time = time.time() - st_1\n","print('Total Time spent TCL 6 dimensional and squeeze() (version3) ', elapsed_time)\n","\n","\n","# Total time spent on Reshape + TCL + squeeze()\n","elapsed_time = time.time() - st\n","print('Total Time spent on Reshape + TCL 6 dimensional +  squeeze() (version 3) ', elapsed_time)\n","\n","print(tempstring)\n","# TRL\n","# TRL input in both cases (with/without reshape) is 3 dimensional \n","# But the ranks are different\n","trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","st = time.time()\n","x6 = trl(x5)\n","elapsed_time = time.time() - st\n","print('Time spent on TRL (input rank : [13,2,2]) ', elapsed_time)\n","\n","\n","trl_3d = tltorch.TRL(input_shape = [30,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","st = time.time()\n","x6_3d = trl_3d(x4_3d)\n","elapsed_time = time.time() - st\n","print('Time spent on TRL (input rank : [30,2,2]) ', elapsed_time)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-R0qfusHsiE","executionInfo":{"status":"ok","timestamp":1683987248835,"user_tz":-210,"elapsed":10646,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"d1c52166-049f-46ac-c511-93aae05f13bc"},"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["Time spent on first convolution Layer  3.1734468936920166\n","Time spent on second convolution Layer  1.7070107460021973\n","\n","######################################\n","\n","\n","Time spent on Reshaping the Tensor  0.35261011123657227\n","Time spent on TCL 6 Dimensional  0.06156492233276367\n","Time spent on squeeze()  0.0011353492736816406\n","Total Time spent TCL 6 dimensional and squeeze()  0.0630791187286377\n","Total Time spent on Reshape + TCL 6 dimensional +  squeeze()  0.4191412925720215\n","\n","######################################\n","\n","\n","Time spent on TCL 3 Dimensional  0.09839797019958496\n","\n","######################################\n","\n","\n","Reshape time using Tensoly Reshape function :  0.001592397689819336\n","Time spent on TCL 6 Dimensional  0.07184123992919922\n","Total Time spent squeeze()  0.0012443065643310547\n","Total Time spent on Reshape + TCL 6 dimensional +  squeeze() with .reshape function  0.07605361938476562\n","\n","######################################\n","\n","\n","Time spent on Reshaping the Tensor (version2)  0.3576040267944336\n","Time spent on TCL 6 Dimensional (version2)  0.06874752044677734\n","Time spent on squeeze() (version2)  8.821487426757812e-05\n","Total Time spent TCL 6 dimensional and squeeze() (version2)  0.07006669044494629\n","Total Time spent on Reshape + TCL 6 dimensional +  squeeze() (version 2)  0.4294731616973877\n","\n","######################################\n","\n","\n","Time spent on Reshaping the Tensor (version3)  0.29130077362060547\n","Time spent on TCL 6 Dimensional (version3)  0.055571556091308594\n","Time spent on squeeze() (version3)  0.00013327598571777344\n","Total Time spent TCL 6 dimensional and squeeze() (version3)  0.057930707931518555\n","Total Time spent on Reshape + TCL 6 dimensional +  squeeze() (version 3)  0.3525862693786621\n","\n","######################################\n","\n","\n","Time spent on TRL (input rank : [13,2,2])  0.0031533241271972656\n","Time spent on TRL (input rank : [30,2,2])  0.00559687614440918\n"]}]},{"cell_type":"markdown","source":[" It is observed that .reshape function performs faster, therefore it is advised to study the base code of .reshape to further improve our Reshape class and forward pass time. \n","\n","\n"," Version 2 still takes longer to execute than original 3D TCL, therefore it has been rejected.  "],"metadata":{"id":"ctSua8cfV8Hl"}},{"cell_type":"code","source":["# torch.as_stride\n","# torch.index_select\n","\n","\n","# tensor = torch.Tensor(np.arange(0,100).reshape(10,10))\n","# temp1 = torch.index_select(tensor,1, torch.tensor(range(0,5)))\n","# torch.index_select(temp1, 0, torch.tensor(range(0,5)))"],"metadata":{"id":"tIrwbzuFSNOR","executionInfo":{"status":"ok","timestamp":1683984287992,"user_tz":-210,"elapsed":5,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["#import tensorflow as tf\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":135},"id":"kBiXDMvuHReb","executionInfo":{"status":"error","timestamp":1683986846192,"user_tz":-210,"elapsed":8,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"6531aff5-0ab1-4f2b-8846-1a116a6f0f06"},"execution_count":126,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-126-c9e013f4a11f>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    temp1[0,0,0,0] = tensor[5,5])\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"]}]},{"cell_type":"code","source":["tensor = torch.Tensor(np.arange(0,100).reshape(10,10))\n","tensor.reshape(2,2,5,5)"],"metadata":{"id":"L5jhFBDxEnOG"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["Y2FNS7AedCzs","BuBPtXZn97kA","gB55xpU8LJzQ","DtQ8p0zwaep7","8Ty910HUSR_x","CvcEY6IiVHOT","A93XlVjHhtJ-","A7xE9gL1xdhE"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
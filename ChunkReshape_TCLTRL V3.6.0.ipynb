{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Kp3FhdQBso0_"},"source":["#Version 3.6.0\n","<hr>\n","Report of forward time spent on MNIST and CIFAR10. Five models for each dataset.\n","\n","1. Base Model\n","2. TRL only Model\n","3. TCL+TRL Model\n","4. ChunkReshape map type 1 + TCL + TRL Model\n","5. ChunkReshape map type 2 + TCL + TRL Model\n","\n","<hr>\n","\n","## Issues:\n","\n","- Study the case of inconsistency in Forward time reports\n","\n","- Reshape time still remains longer\n","\n","## Attempts :\n","\n","- Try to generate and empty output from init\n","\n","- Try to replicate the process using built-in functions\n","\n","The result of these attempts are reported at the last code blocks"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lRUeJm_OTOdV"},"source":["#Reshape Tensor to a higher dimensional Tensor\n","\n","In this notetbook, we study the case of reshaping a tensor (i.e 3-Tensor) to a \n","higher dimensional tensor (i.e 6-Tensor) and its effect on Tensor Contraction and Regression Layer as previously studied at official Tensorly documentation website.\n","\n","\n","The process is as follow:\n","1. Given a n-dimensional tensor, there are n modes and the first mode (mode-1) is considered to be the mode responsible for handling the batch index.\n","2. There are multiple fibers and the goal is to break them into different chunks and rearrange them in a higher dimensional tensor.\n","3. Breaking the fibers with coefficients such as $l_1$, etc; Whereas each mode $i$ is split into $l_i$ equal length chunks.\n","4. The newly made tensor is of the double dimension of the original tensor, for example if the original tensor is 3-dimensional then the new tensor is 6-dimensional.\n","5. We study to approaches in spliting the modes:\n","  - normal split  :  $[0,\\dots,l_i],[l_i+1,\\dots,2l_i],\\dots$\n","  - down sampling :  Usually for the cases when $l_i$ is 2, odd and even indices. \n","6. According to the types of splits there are 2 mapping functions (3-Tensor):\n","  - map 1 : $B(i_1,i_2,i_3,j_1,j_2,j_3) = A(j_1 + (i_1 - 1)M_1, j_2 + (i_2 - 1)M_2, j_3 + (i_3 - 1)M_3)$\n","  - map 2 : $B(i_1,i_2,i_3,j_1,j_2,j_3) = A(M_1(j_1 - 1) + i_1, M_2(j_2 - 1) + i_2), M_3(j_3 - 1) + i_3$\n","  - Where $M_i$ is $\\frac{I_i}{l_i}$, and $I_i$ is the original size of model $i$.\n","7. We can easily expand the maps to fit n-dimensional tensors as well.\n","\n","\n","For this case we create ChunkReshape class where we can do the just that. "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8209,"status":"ok","timestamp":1683989399274,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"a7iQS-r3Yz_k","outputId":"7abf7ea0-7ebd-4252-a5b4-78fc8593918a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorly-torch in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.4.0)\n","Requirement already satisfied: numpy in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly-torch) (1.24.3)\n","Requirement already satisfied: scipy in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly-torch) (1.10.1)\n","Requirement already satisfied: nose in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly-torch) (1.3.7)\n","Requirement already satisfied: tensorly in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.8.1)\n","Requirement already satisfied: numpy in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly) (1.24.3)\n","Requirement already satisfied: scipy in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly) (1.10.1)\n"]}],"source":["# Necessary Packages \n","!pip install tensorly-torch \n","!pip install tensorly\n","\n","import tltorch # TCL and TRL\n","import tensorly as tl # Tensor operation \n","import torch   #  Neural Network\n","from torch import nn # Neural Network\n","from torch.autograd import Variable # Tensor input\n","import torch.optim as optim # Optimization\n","from torchvision import datasets, transforms # Datasets and transoforms\n","import torchvision # Data Loader\n","import torch.nn.functional as F # Activation Functions\n","\n","import numpy as np # Numerical operations\n","import itertools # Generate indices\n","\n","import matplotlib.pyplot as plt # Generate plots\n","import pandas as pd # Save the result as a sheet\n","\n","import time # execuation time\n","import os # to save the results"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Y2FNS7AedCzs"},"source":["# Original Chunk Reshape\n","\n","Original as in the first model to be created."]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":837,"status":"ok","timestamp":1683978958398,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"3ft6MV6fTLgr"},"outputs":[],"source":["# class ChunkReshape(nn.Module):\n","#     def __init__(self, input_size, L, map_type=1, device=None, dtype=None):\n","#         super().__init__()\n","\n","#         if isinstance(input_size, int):\n","#             self.input_size = (input_size,)\n","#         else:\n","#             self.input_size = tuple(input_size)\n","#         if isinstance(L, int):\n","#             self.L = (L,)\n","#         else:\n","#             self.L = tuple(L)\n","#         if map_type == 1 or self.L.count(2) != len(self.L):\n","#             self.map_type = 1\n","#         else:\n","#             self.map_type = 2\n","\n","#         self.device = device\n","#         self.dtype = dtype\n","\n","#         self.M = []\n","#         for i, _ in enumerate(self.L):\n","#             if self.input_size[i] % self.L[i] != 0:\n","#                 raise RuntimeError(f'Bad L : input_size {self.input_size[i]} is not divisible by L size {self.L[i]}')\n","#             self.M.append(int(self.input_size[i] / self.L[i]))\n","\n","#         self.lists_indices = []\n","#         for i in range(len((list(self.L) + self.M))):\n","#             self.lists_indices.append(np.arange((list(self.L) + self.M)[i]))\n","\n","#         self.indices = np.array([p for p in itertools.product(*self.lists_indices)])\n","\n","#     def forward(self, x):\n","#         new_shapes = tuple([x.shape[0]] + list(self.L) + self.M)\n","#         out = torch.empty(new_shapes, device=self.device, dtype=self.dtype)\n","\n","#         if self.map_type == 1:\n","#             for index_B in self.indices:\n","#                 out_index = [slice(None)] + list(index_B[:len(self.L)])\n","#                 x_index = [slice(None)] + [index_B[i] * self.M[i] + index_B[i + len(self.L)] for i in range(len(self.L))]\n","#                 out[out_index] = x[x_index]\n","#         else:\n","#             for index_B in self.indices:\n","#                 out_index = [slice(None)] + list(index_B[:len(self.L)])\n","#                 x_index = [slice(None)] + [index_B[i + len(self.L)] * 2 + index_B[i] for i in range(len(self.L))]\n","#                 out[out_index] = x[x_index]\n","\n","#         return out\n","\n","\n","class ChunkReshape(nn.Module):\n","    def __init__(self, input_size, L, batch_size, map_type=1, device=None, dtype=None):\n","        super().__init__()\n","\n","        if isinstance(input_size, int):\n","            self.input_size = (input_size,)\n","        else:\n","            self.input_size = tuple(input_size)\n","        if isinstance(L, int):\n","            self.L = (L,)\n","        else:\n","            self.L = tuple(L)\n","        if map_type == 1 or self.L.count(2) != len(self.L):\n","            self.map_type = 1\n","        else:\n","            self.map_type = 2\n","\n","        self.device = device\n","        self.dtype = dtype\n","        self.batch_size = batch_size\n","\n","        self.M = []\n","        for i, _ in enumerate(self.L):\n","            if self.input_size[i] % self.L[i] != 0:\n","                raise RuntimeError(\n","                    f'Bad L : input_size {self.input_size[i]} is not divisible by L size {self.L[i]}')\n","            self.M.append(int(self.input_size[i] / self.L[i]))\n","\n","        self.lists_indices = []\n","        for i in range(len((list(self.L) + self.M))):\n","            self.lists_indices.append(np.arange((list(self.L) + self.M)[i]))\n","\n","        self.indices = np.array([p for p in itertools.product(*self.lists_indices)])\n","\n","        self.new_shapes = tuple([self.batch_size] + list(self.L) + self.M)\n","\n","    def forward(self, x):\n","        x = x.view(self.batch_size, *self.input_size)\n","        out = x.new_empty(self.new_shapes)\n","\n","        if self.map_type == 1:\n","\n","            for index_B in self.indices:\n","\n","                code = '' + 'out[:,'\n","                map_B_string = ','.join(map(str, index_B))\n","                code += map_B_string + ']'\n","\n","                index_A = []\n","                for ii in range(len(index_B)):\n","                    index_A.append(index_B[ii] * self.M[ii] + index_B[ii + len(self.L)])\n","                    if ii == len(self.L) - 1:\n","                        map_A_string = ','.join(map(str, index_A))\n","                        code += '= x[:,'\n","                        code += map_A_string + ']'\n","                        exec(code)\n","                        break\n","\n","            return out\n","\n","        else:\n","\n","            for index_B in self.indices:\n","\n","                code = '' + 'out[:,'\n","                map_B_string = ','.join(map(str, index_B))\n","                code += map_B_string + ']'\n","\n","                index_A = []\n","                for ii in range(len(index_B)):\n","                    index_A.append(index_B[ii + len(self.L)] * 2 + index_B[ii])\n","                    if ii == len(self.L) - 1:\n","                        map_A_string = ','.join(map(str, index_A))\n","                        code += '= x[:,'\n","                        code += map_A_string + ']'\n","                        exec(code)\n","                        break\n","            return out\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BuBPtXZn97kA"},"source":["# Version  2 of chunk reshape\n","\n","Another version of chunk reshape to study the case of creating output from the init and then calculating the time spent."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683980305456,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"cHhz-ngs-LQq"},"outputs":[],"source":["class ChunkReshapeVersion2(nn.Module):\n","    def __init__(self, input_size, L, batch_size, map_type=1, device=None, dtype=None):\n","        super().__init__()\n","\n","        if isinstance(input_size, int):\n","            self.input_size = (input_size,)\n","        else:\n","            self.input_size = tuple(input_size)\n","        if isinstance(L, int):\n","            self.L = (L,)\n","        else:\n","            self.L = tuple(L)\n","        if map_type == 1 or self.L.count(2) != len(self.L):\n","            self.map_type = 1\n","        else:\n","            self.map_type = 2\n","\n","        self.device = device\n","        self.dtype = dtype\n","        self.batch_size = batch_size\n","\n","        self.M = []\n","        for i, _ in enumerate(self.L):\n","            if self.input_size[i] % self.L[i] != 0:\n","                raise RuntimeError(f'Bad L : input_size {self.input_size[i]} is not divisible by L size {self.L[i]}')\n","            self.M.append(int(self.input_size[i] / self.L[i]))\n","\n","        self.lists_indices = []\n","        for i in range(len((list(self.L) + self.M))):\n","            self.lists_indices.append(np.arange((list(self.L) + self.M)[i]))\n","\n","        self.indices = np.array([p for p in itertools.product(*self.lists_indices)])\n","\n","        self.new_shapes = tuple([self.batch_size] + list(self.L) + self.M)\n","\n","    def forward(self, x):\n","        out = torch.empty(self.new_shapes, device=self.device, dtype=self.dtype)\n","\n","        if self.map_type == 1:\n","            for index_B in self.indices:\n","                out_index = [slice(None)] + list(index_B[:len(self.L)])\n","                x_index = [slice(None)] + [index_B[i] * self.M[i] + index_B[i + len(self.L)] for i in range(len(self.L))]\n","                out[out_index] = x[x_index]\n","        else:\n","            for index_B in self.indices:\n","                out_index = [slice(None)] + list(index_B[:len(self.L)])\n","                x_index = [slice(None)] + [index_B[i + len(self.L)] * 2 + index_B[i] for i in range(len(self.L))]\n","                out[out_index] = x[x_index]\n","\n","        return out\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zNUagJIaa1xj"},"source":["# Version 3 of chunk reshape"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683987160971,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"fm0H_p8xa3-9"},"outputs":[],"source":["class ChunkReshapeVersion3(nn.Module):\n","    def __init__(self, input_size, L, batch_size, map_type=1, device=None, dtype=None):\n","        super().__init__()\n","\n","        if isinstance(input_size, int):\n","            self.input_size = (input_size,)\n","        else:\n","            self.input_size = tuple(input_size)\n","        if isinstance(L, int):\n","            self.L = (L,)\n","        else:\n","            self.L = tuple(L)\n","        if map_type == 1 or self.L.count(2) != len(self.L):\n","            self.map_type = 1\n","        else:\n","            self.map_type = 2\n","\n","        self.device = device\n","        self.dtype = dtype\n","        self.batch_size = batch_size\n","\n","        self.M = []\n","        for i, _ in enumerate(self.L):\n","            if self.input_size[i] % self.L[i] != 0:\n","                raise RuntimeError(f'Bad L : input_size {self.input_size[i]} is not divisible by L size {self.L[i]}')\n","            self.M.append(int(self.input_size[i] / self.L[i]))\n","\n","        self.lists_indices = []\n","        for i in range(len((list(self.L) + self.M))):\n","            self.lists_indices.append(np.arange((list(self.L) + self.M)[i]))\n","\n","        self.indices = np.array([p for p in itertools.product(*self.lists_indices)])\n","\n","        self.new_shapes = tuple([self.batch_size] + list(self.L) + self.M)\n","\n","    def forward(self, x):\n","        out = torch.empty(self.new_shapes, device=self.device, dtype=self.dtype)\n","\n","        if self.map_type == 1:\n","            for index_B in self.indices:\n","                out_index = [slice(None)] + list(index_B[:len(self.L)])\n","                x_index = [slice(None)] + [index_B[i] * self.M[i] + index_B[i + len(self.L)] for i in range(len(self.L))]\n","                out[out_index] = x[x_index]\n","        else:\n","            for index_B in self.indices:\n","                out_index = [slice(None)] + list(index_B[:len(self.L)])\n","                x_index = [slice(None)] + [index_B[i + len(self.L)] * 2 + index_B[i] for i in range(len(self.L))]\n","                out[out_index] = x[x_index]\n","\n","        return out\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gB55xpU8LJzQ"},"source":["# MNIST Dataset\n","\n","- A Large batch size is required to notice the difference between models in <code> forward() </code>\n","\n","- Defined as function to generalize in <b> Report Section </b>\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1235,"status":"ok","timestamp":1683979186715,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"XERYYb1gLJLi","outputId":"3ebe15a2-5626-4143-cd61-f449353b94bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%"]},{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n","Extracting ./data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%"]},{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n","Extracting ./data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/MNIST\\raw\n","\n","Batch size: 200\n","Device: cuda\n","Number of training batches: 300\n","Number of testing batches: 50\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Big Batch_size to notice the difference\n","\n","# Defined as a function to generalize in Report Section\n","\n","# to run on CPU, uncomment the following line:\n","#device = 'cpu'\n","\n","MNIST_train_dataset = datasets.MNIST('./data/', train=True, download=True,\n","                        transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                        ])) \n","MNIST_test_dataset = datasets.MNIST('./data/', train=False, download=True,\n","                        transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                        ]))\n","\n","\n","def MNIST_loader(_batch_size = 200 ,_device = 'cuda'):\n","\n","    batch_size = _batch_size\n","    device = _device   \n","\n","    train_loader_mnist = torch.utils.data.DataLoader(MNIST_train_dataset,\n","          batch_size=batch_size, shuffle=True)\n","    test_loader_mnist = torch.utils.data.DataLoader(MNIST_test_dataset,\n","          batch_size=batch_size, shuffle=True)\n","    \n","    return batch_size, device, train_loader_mnist, test_loader_mnist\n","\n","# Set batch size and device\n","batch_size = 200\n","device = 'cuda'  # Use 'cpu' if you want to run on CPU\n","\n","# Call MNIST_loader\n","batch_size, device, train_loader_mnist, test_loader_mnist = MNIST_loader(batch_size, device)\n","\n","# Print some information to verify\n","print(f\"Batch size: {batch_size}\")\n","print(f\"Device: {device}\")\n","print(f\"Number of training batches: {len(train_loader_mnist)}\")\n","print(f\"Number of testing batches: {len(test_loader_mnist)}\")\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LmO9rDmH6P9G"},"source":["## Example of Chunk Reshape of a Tensor - MNIST"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":518,"status":"ok","timestamp":1683979336069,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"SKkxf1HM6TZT","outputId":"bb23c967-302b-4684-8898-968dfd188a83"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input shape  torch.Size([200, 1, 28, 28])\n","Input shape after convolution kernel 5 and max pooling kernel 2  torch.Size([200, 20, 12, 12])\n","Input shape after another convolution kernel 5 and max pooling kernel 2  torch.Size([200, 50, 4, 4])\n","Ready for Reshape Using L = [2,2,2] and map type 1\n","output size of Chunk Reshape torch.Size([200, 2, 2, 2, 25, 2, 2])\n"]},{"ename":"AttributeError","evalue":"'TCL' object has no attribute 'factor_6'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[36], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39moutput size of Chunk Reshape\u001b[39m\u001b[39m'\u001b[39m, x3\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     23\u001b[0m \u001b[39m# TCL \u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m tcl \u001b[39m=\u001b[39m tltorch\u001b[39m.\u001b[39;49mTCL(input_shape\u001b[39m=\u001b[39;49m[\u001b[39m200\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m25\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m], rank\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m13\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m])\n\u001b[0;32m     26\u001b[0m x4 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(tcl(x3))\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39moutput size of TCL\u001b[39m\u001b[39m'\u001b[39m, x4\u001b[39m.\u001b[39mshape)\n","File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tltorch\\factorized_layers\\tensor_contraction_layers.py:67\u001b[0m, in \u001b[0;36mTCL.__init__\u001b[1;34m(self, input_shape, rank, verbose, bias, device, dtype, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_parameter(\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_parameters()\n","File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tltorch\\factorized_layers\\tensor_contraction_layers.py:91\u001b[0m, in \u001b[0;36mTCL.reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Sets the parameters' values randomly\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[0;32m     86\u001b[0m \u001b[39mTodo\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m----\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39mThis may be renamed to init_from_random for consistency with TensorModules\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morder):\n\u001b[1;32m---> 91\u001b[0m     init\u001b[39m.\u001b[39mkaiming_uniform_(\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfactor_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m), a\u001b[39m=\u001b[39mmath\u001b[39m.\u001b[39msqrt(\u001b[39m5\u001b[39m))\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     bound \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_shape[\u001b[39m0\u001b[39m])\n","File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n","\u001b[1;31mAttributeError\u001b[0m: 'TCL' object has no attribute 'factor_6'"]}],"source":["# Dataset Loaders\n","batch_size, device, train_loader_mnist, test_loader_mnist = MNIST_loader()\n","\n","# Get a batch from dataset\n","examples_mnist = enumerate(train_loader_mnist)\n","batch_idx, (example_data_mnist, example_targets_mnist) = next(examples_mnist)\n","\n","# One forward through Net\n","print('Input shape ', example_data_mnist.shape)\n","conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","x1 = F.relu(F.max_pool2d(conv1(example_data_mnist), 2))\n","print('Input shape after convolution kernel 5 and max pooling kernel 2 ', x1.shape)\n","conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","x2 = F.relu(F.max_pool2d(conv2(x1), 2))\n","print('Input shape after another convolution kernel 5 and max pooling kernel 2 ', x2.shape)\n","print('Ready for Reshape Using L = [2,2,2] and map type 1')\n","\n","# With Reshape\n","Chunk_Reshape = ChunkReshape(input_size=[50, 4, 4], L=[2, 2, 2], batch_size=batch_size, map_type=1)\n","x3 = Chunk_Reshape(x2)\n","print('output size of Chunk Reshape', x3.shape)\n","\n","# TCL \n","tcl = tltorch.TCL(input_shape=[200, 2, 2, 2, 25, 2, 2], rank=[1, 1, 1, 13, 2, 2])\n","\n","x4 = F.relu(tcl(x3))\n","print('output size of TCL', x4.shape)\n","x5 = x4.squeeze()\n","print('output size of TCL with squeeze() ', x5.shape)\n","\n","# TRL \n","trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","x6 = trl(x5)\n","print('output size of TRL', x6.shape)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DtQ8p0zwaep7"},"source":["# CIFAR10 Dataset\n","\n","- Same Batch size same Issues as MNIST"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9743,"status":"ok","timestamp":1683979350743,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"8_MFjvNmtgP4","outputId":"d52ee4b5-2dae-4c50-b81c-ab6179288e76"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data/\n","Files already downloaded and verified\n"]},{"data":{"text/plain":["(200,\n"," 'cuda',\n"," <torch.utils.data.dataloader.DataLoader at 0x215c39754c0>,\n"," <torch.utils.data.dataloader.DataLoader at 0x215c3975910>)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Big Batch_size to notice the difference\n","\n","# Defined as a function to generalize in Report Section\n","\n","# to run on CPU, uncomment the following line:\n","#device = 'cpu'\n","\n","CIFAR10_train_dataset = datasets.CIFAR10('./data/', train=True, download=True,\n","                        transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n","                        ])) \n","CIFAR10_test_dataset = datasets.CIFAR10('./data/', train=False, download=True,\n","                        transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n","                        ]))\n","\n","\n","\n","def CIFAR10_loader(_batch_size = 200 ,_device = 'cuda'):\n","\n","    batch_size = _batch_size\n","    device = _device   \n","\n","    train_loader_cifar10 = torch.utils.data.DataLoader(CIFAR10_train_dataset,\n","          batch_size=batch_size, shuffle=True)\n","    test_loader_cifar10 = torch.utils.data.DataLoader(CIFAR10_test_dataset,\n","          batch_size=batch_size, shuffle=True)\n","    \n","    return batch_size, device, train_loader_cifar10, test_loader_cifar10\n","\n","\n","# Initialize \n","CIFAR10_classes = ['plane', 'car', 'bird', 'cat',\n","                  'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","CIFAR10_loader()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MZVyCtN6b_RH"},"source":["## Example of Chunk Reshape of a Tensor - CIFAR10"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":562,"status":"ok","timestamp":1683979358949,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"3a3pq7ACcAvs","outputId":"1fa6d7e3-da96-4785-a0ab-31cff153bdc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input shape  torch.Size([200, 3, 32, 32])\n","Input shape after convolution kernel 5 and max pooling kernel 2  torch.Size([200, 20, 14, 14])\n","Input shape after another convolution kernel 6 and max pooling kernel 2  torch.Size([200, 50, 4, 4])\n","Ready for Reshape Using L = [2,2,2] and map type 1\n"]},{"ename":"TypeError","evalue":"__init__() missing 1 required positional argument: 'batch_size'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[34], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mReady for Reshape Using L = [2,2,2] and map type 1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[39m# With Reshape\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m Chunk_Reshape \u001b[39m=\u001b[39m ChunkReshape(input_size \u001b[39m=\u001b[39;49m [\u001b[39m50\u001b[39;49m,\u001b[39m4\u001b[39;49m,\u001b[39m4\u001b[39;49m], L \u001b[39m=\u001b[39;49m [\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m], map_type \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     18\u001b[0m x3 \u001b[39m=\u001b[39m Chunk_Reshape(x2)\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39moutput size of Chunk Reshape\u001b[39m\u001b[39m'\u001b[39m, x3\u001b[39m.\u001b[39mshape)\n","\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'batch_size'"]}],"source":["# Dataset Loaders\n","batch_size, device, train_loader_cifar10, test_loader_cifar10 = CIFAR10_loader()\n","\n","# Get a batch from dataset\n","examples_cifar10 = enumerate(train_loader_cifar10)\n","batch_idx, (example_data_cifar10, example_targets_cifar10) = next(examples_cifar10)\n","\n","print('Input shape ', example_data_cifar10.shape)\n","conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","x1 = F.relu(F.max_pool2d(conv1(example_data_cifar10), 2))\n","print('Input shape after convolution kernel 5 and max pooling kernel 2 ', x1.shape)\n","conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","x2 = F.relu(F.max_pool2d(conv2(x1), 2))\n","print('Input shape after another convolution kernel 6 and max pooling kernel 2 ', x2.shape)\n","print('Ready for Reshape Using L = [2,2,2] and map type 1')\n","# With Reshape\n","Chunk_Reshape = ChunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 1)\n","x3 = Chunk_Reshape(x2)\n","print('output size of Chunk Reshape', x3.shape)\n","# TCL \n","tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","x4 = F.relu(tcl(x3))\n","print('output size of TCL', x4.shape)\n","x5 = x4.squeeze()\n","print('output size of TCL with squeeze() ', x5.shape)\n","# TRL \n","trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","x6 = trl(x5)\n","print('output size of TRL', x6.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8Ty910HUSR_x"},"source":["# Create Networks"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HDvm9KSq8IM6"},"source":["## MNIST Models\n","\n","- Base Model\n","- TRL only Model\n","- TCL + TRL Model\n","- Chunk Reshape map type 1 + TCL + TRL Model\n","- Chunk Reshape map type 2 + TCL + TRL Model"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683979655364,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"al9yqDufR5cL"},"outputs":[],"source":["\n","# Base Model\n","\n","class MNIST_Net_base(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_base, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(800, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1,800)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# TRL only Model\n","\n","class MNIST_Net_TRL(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_TRL, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.trl = tltorch.TRL(input_shape = [50,4,4] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# TCL + TRL Model\n","\n","class MNIST_Net_TCL_TRL(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_TCL_TRL, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.tcl = tltorch.TCL(input_shape= [50,4,4], rank=[30,2,2])\n","        self.trl = tltorch.TRL(input_shape = [30,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = F.relu(self.tcl(x))\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","# Chunk Reshape map type 1 + TCL + TRL Model\n","\n","class MNIST_Net_chunk_TCL_TRL_map1(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_chunk_TCL_TRL_map1, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.chunk = ChunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 1, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","\n","# Chunk Reshape map type 2 + TCL + TRL Model\n","\n","class MNIST_Net_chunk_TCL_TRL_map2(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net_chunk_TCL_TRL_map2, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.chunk = ChunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 2, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# Chunk Reshape map type 1 + TCL + TRL Model version 2 of chunk reshape\n","\n","class MNIST_Net_chunk_TCL_TRL_map1_version2(nn.Module):\n","    def __init__(self, _batch_size):\n","        super(MNIST_Net_chunk_TCL_TRL_map1_version2, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.chunk = ChunkReshapeVersion2(input_size = [50,4,4], L = [2,2,2], batch_size= _batch_size , map_type = 1, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","\n","# Chunk Reshape map type 2 + TCL + TRL Model version 2 of chunk reshape\n","\n","class MNIST_Net_chunk_TCL_TRL_map2_version2(nn.Module):\n","    def __init__(self, _batch_size):\n","        super(MNIST_Net_chunk_TCL_TRL_map2_version2, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.chunk = ChunkReshapeVersion2(input_size = [50,4,4], L = [2,2,2], batch_size = _batch_size, map_type = 2, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"m8pmzLwad6AC"},"source":["## CIFAR10 Models\n","\n","- Base Model\n","- TRL only Model\n","- TCL + TRL Model\n","- Chunk Reshape map type 1 + TCL + TRL Model\n","- Chunk Reshape map type 2 + TCL + TRL Model"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":515,"status":"ok","timestamp":1683979688994,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"KxK_CL9nekgo"},"outputs":[],"source":["\n","# Base Model\n","\n","class CIFAR10_Net_base(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_base, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(800, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1,800)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# TRL only Model\n","\n","class CIFAR10_Net_TRL(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_TRL, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.trl = tltorch.TRL(input_shape = [50,4,4] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# TCL + TRL Model\n","\n","class CIFAR10_Net_TCL_TRL(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_TCL_TRL, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.tcl = tltorch.TCL(input_shape= [50,4,4], rank=[30,2,2])\n","        self.trl = tltorch.TRL(input_shape = [30,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = F.relu(self.tcl(x))\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","# Chunk Reshape map type 1 + TCL + TRL Model\n","\n","class CIFAR10_Net_chunk_TCL_TRL_map1(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_chunk_TCL_TRL_map1, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.chunk = ChunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 1, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","\n","# Chunk Reshape map type 2 + TCL + TRL Model\n","\n","class CIFAR10_Net_chunk_TCL_TRL_map2(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10_Net_chunk_TCL_TRL_map2, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.chunk = ChunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 2, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","# Chunk Reshape map type 1 + TCL + TRL Model version 2 of chunk reshape\n","\n","class CIFAR10_Net_chunk_TCL_TRL_map1_version2(nn.Module):\n","    def __init__(self, _batch_size):\n","        super(CIFAR10_Net_chunk_TCL_TRL_map1_version2, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.chunk = ChunkReshapeVersion2(input_size = [50,4,4], L = [2,2,2], batch_size = _batch_size, map_type = 1, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)\n","\n","\n","\n","# Chunk Reshape map type 2 + TCL + TRL Model version 2 of chunk reshape\n","\n","class CIFAR10_Net_chunk_TCL_TRL_map2_version2(nn.Module):\n","    def __init__(self, _batch_size):\n","        super(CIFAR10_Net_chunk_TCL_TRL_map2_version2, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=6)\n","        self.chunk = ChunkReshapeVersion2(input_size = [50,4,4], L = [2,2,2], batch_size = _batch_size, map_type = 2, device = 'cuda')\n","        # to make it easier we contract L values to rank 1\n","        self.tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","        self.trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = self.chunk(x)\n","        x = F.relu(self.tcl(x)).squeeze()\n","        x = self.trl(x)\n","        return F.log_softmax(x, 1)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CvcEY6IiVHOT"},"source":["# Models, Optimizers ,and Criterions"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":494,"status":"ok","timestamp":1683979766568,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"Z7cp4a1cfjgk"},"outputs":[],"source":["# MNIST \n","\n","\n","MNIST_Models = [\n","    MNIST_Net_base(),\n","    MNIST_Net_TRL(),\n","    MNIST_Net_TCL_TRL(),\n","    MNIST_Net_chunk_TCL_TRL_map1(),\n","    MNIST_Net_chunk_TCL_TRL_map2(), \n","]\n","\n","\n","MNIST_Optimizers = [\n","    optim.SGD(MNIST_Models[0].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(MNIST_Models[1].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(MNIST_Models[2].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(MNIST_Models[3].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(MNIST_Models[4].parameters(), lr=0.01, momentum=0.9)\n","]\n","\n","MNIST_Criterion = [\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss()\n","]\n","\n","\n","# CIFAR10\n","\n","CIFAR10_Models= [\n","    CIFAR10_Net_base(),\n","    CIFAR10_Net_TRL(),\n","    CIFAR10_Net_TCL_TRL(),\n","    CIFAR10_Net_chunk_TCL_TRL_map1(),\n","    CIFAR10_Net_chunk_TCL_TRL_map2()\n","]\n","\n","CIFAR10_Optimizers = [\n","    optim.SGD(CIFAR10_Models[0].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(CIFAR10_Models[1].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(CIFAR10_Models[2].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(CIFAR10_Models[3].parameters(), lr=0.01, momentum=0.9),\n","    optim.SGD(CIFAR10_Models[4].parameters(), lr=0.01, momentum=0.9)\n","]\n","\n","CIFAR10_Criterion = [\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss(),\n","    nn.CrossEntropyLoss()\n","]\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"A93XlVjHhtJ-"},"source":["# Check The Results for one Forward pass on MNIST and CIFAR10"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":601,"status":"ok","timestamp":1683979771388,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"8bzUPZhGiBIl"},"outputs":[],"source":["models_names = ['base', 'TRL only', 'TCL + TRL', 'Chunk Reshape map 1 + TCL + TRL', 'Chunk Reshape map 2 + TCL + TRL']"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pARWssTGh6m3"},"source":["## MNIST (Report on a single batch forward operation)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1551,"status":"ok","timestamp":1683979774787,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"uC03n9u0hzSp","outputId":"d918c21a-695d-43e8-c623-f0a87340f899"},"outputs":[{"name":"stdout","output_type":"stream","text":["#### Execution time one forward pass on batch size (200) MNIST Dataset is 4.668381929397583 Model Type : base\n","#### Execution time one forward pass on batch size (200) MNIST Dataset is 0.00412440299987793 Model Type : TRL only\n","#### Execution time one forward pass on batch size (200) MNIST Dataset is 0.003754138946533203 Model Type : TCL + TRL\n"]},{"ename":"RuntimeError","evalue":"The expanded size of the tensor (2) must match the existing size (200) at non-singleton dimension 3.  Target sizes: [200, 25, 2, 2].  Tensor sizes: [200]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[28], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[39m=\u001b[39m _model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m st \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> 6\u001b[0m output \u001b[39m=\u001b[39m model(example_data_mnist\u001b[39m.\u001b[39;49mto(device))\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m st\n\u001b[0;32m      8\u001b[0m \u001b[39m#time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[24], line 70\u001b[0m, in \u001b[0;36mMNIST_Net_chunk_TCL_TRL_map1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(F\u001b[39m.\u001b[39mmax_pool2d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x), \u001b[39m2\u001b[39m))\n\u001b[0;32m     69\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(F\u001b[39m.\u001b[39mmax_pool2d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x), \u001b[39m2\u001b[39m))\n\u001b[1;32m---> 70\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk(x)\n\u001b[0;32m     71\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtcl(x))\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     72\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrl(x)\n","File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36mChunkReshape.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m         out_index \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(index_B[:\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)])\n\u001b[0;32m     40\u001b[0m         x_index \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)] \u001b[39m+\u001b[39m [index_B[i] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mM[i] \u001b[39m+\u001b[39m index_B[i \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL))]\n\u001b[1;32m---> 41\u001b[0m         out[out_index] \u001b[39m=\u001b[39m x[x_index]\n\u001b[0;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[39mfor\u001b[39;00m index_B \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices:\n","\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (2) must match the existing size (200) at non-singleton dimension 3.  Target sizes: [200, 25, 2, 2].  Tensor sizes: [200]"]}],"source":["# MNIST\n","\n","for index,_model in enumerate(MNIST_Models):\n","    model = _model.to(device)\n","    st = time.time()\n","    output = model(example_data_mnist.to(device)).to(device)\n","    elapsed_time = time.time() - st\n","    #time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n","    print(f'#### Execution time one forward pass on batch size ({batch_size}) MNIST Dataset is {elapsed_time} Model Type : {models_names[index]}')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"n399dFLxkFsn"},"source":["## CIFAR10  (Report on a single batch forward operation)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":564,"status":"ok","timestamp":1683979784671,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"1OfTBsCRkCui","outputId":"7e5e4c5b-a1c4-4f65-dec0-afc689f5c93c"},"outputs":[{"name":"stdout","output_type":"stream","text":["#### Execution time one forward pass on batch size (200) CIFAR10 Dataset is 0.015923500061035156 Model Type : base\n","#### Execution time one forward pass on batch size (200) CIFAR10 Dataset is 0.0029630661010742188 Model Type : TRL only\n","#### Execution time one forward pass on batch size (200) CIFAR10 Dataset is 0.003987789154052734 Model Type : TCL + TRL\n"]},{"ename":"RuntimeError","evalue":"The expanded size of the tensor (2) must match the existing size (200) at non-singleton dimension 3.  Target sizes: [200, 25, 2, 2].  Tensor sizes: [200]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[29], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[39m=\u001b[39m _model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m st \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> 6\u001b[0m output \u001b[39m=\u001b[39m model(example_data_cifar10\u001b[39m.\u001b[39;49mto(device))\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m st\n\u001b[0;32m      8\u001b[0m \u001b[39m# time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[25], line 70\u001b[0m, in \u001b[0;36mCIFAR10_Net_chunk_TCL_TRL_map1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(F\u001b[39m.\u001b[39mmax_pool2d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x), \u001b[39m2\u001b[39m))\n\u001b[0;32m     69\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(F\u001b[39m.\u001b[39mmax_pool2d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x), \u001b[39m2\u001b[39m))\n\u001b[1;32m---> 70\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk(x)\n\u001b[0;32m     71\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtcl(x))\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     72\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrl(x)\n","File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36mChunkReshape.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m         out_index \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(index_B[:\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)])\n\u001b[0;32m     40\u001b[0m         x_index \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)] \u001b[39m+\u001b[39m [index_B[i] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mM[i] \u001b[39m+\u001b[39m index_B[i \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL))]\n\u001b[1;32m---> 41\u001b[0m         out[out_index] \u001b[39m=\u001b[39m x[x_index]\n\u001b[0;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[39mfor\u001b[39;00m index_B \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices:\n","\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (2) must match the existing size (200) at non-singleton dimension 3.  Target sizes: [200, 25, 2, 2].  Tensor sizes: [200]"]}],"source":["# CIFAR10\n","\n","for index,_model in enumerate(CIFAR10_Models):\n","    model = _model.to(device)\n","    st = time.time()\n","    output = model(example_data_cifar10.to(device)).to(device)\n","    elapsed_time = time.time() - st\n","    # time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n","    print(f'#### Execution time one forward pass on batch size ({batch_size}) CIFAR10 Dataset is {elapsed_time} Model Type : {models_names[index]}')\n","\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"A7xE9gL1xdhE"},"source":["# Report Section\n","\n","In this section we report different forward passes on different batch sizes and different instances in a csv sheet."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCfEBWPQxq31"},"outputs":[],"source":["# PATH\n","DIRECTORY = './Report'\n","PATH = DIRECTORY + '/reportV3.5.0.csv'\n","if not os.path.exists(DIRECTORY):\n","   os.mkdir(DIRECTORY)\n","\n","# Dataframe\n","columns = [\n","    'Dataset',\n","    'batch_size',\n","    'model',\n","    'forward pass time'\n","]\n","\n","dataframe = pd.DataFrame(columns = columns )\n","\n","datasets = ['MNIST', 'CIFAR10']\n","batch_sizes = [16, 200, 1000, 20000, 60000]\n","# models_names = ['base', 'TRL only', 'TCL + TRL', 'Chunk Reshape map 1 + TCL + TRL', 'Chunk Reshape map 2 + TCL + TRL']\n","\n","for dataset in datasets:\n","    # Get the dataset\n","    for i, model_name in enumerate(models_names):\n","        # Get model and its name\n","        for b in batch_sizes:\n","            # Set a batch size\n","            if dataset == 'MNIST':\n","                # Dataset loaders and models\n","                batch_size, device, train_loader, test_loader = MNIST_loader(_batch_size = b, _device = 'cuda')\n","                model = MNIST_Models[i].to(device)\n","            else:\n","                # Dataset loaders and models\n","                batch_size, device, train_loader, test_loader = CIFAR10_loader(_batch_size = b, _device = 'cuda')\n","                model = CIFAR10_Models[i].to(device)\n","            \n","            # Get one batch of dataset\n","            examples = enumerate(train_loader)\n","            batch_idx, (example_data, example_targets) = next(examples)\n","\n","            # Calculate time spent on forward pass\n","            st = time.time()\n","            output = model(example_data.to(device)).to(device)\n","            elapsed_time = time.time() - st\n","\n","\n","            # dataframe entry\n","            entry = {\n","                columns[0]: [dataset],\n","                columns[1]: [batch_size],\n","                columns[2]: [model_name],\n","                columns[3]: [elapsed_time]\n","            }\n","            # append to dataframe\n","            dataframe = pd.concat([dataframe, pd.DataFrame(entry)], ignore_index = True )\n","            dataframe.reset_index()\n","\n","    #break # To only display MNIST results \n","\n","# Save to file\n","dataframe.to_csv(PATH)\n","# show dataframe\n","display(dataframe)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LX40O15XHuCL"},"source":["# Study The case of inconsistency in forward time\n","\n","- Possible Cause : Not Optimal implementation of TCL or/and TRL in tensorly-torch package (status : <font color ='red' > Rejected</font> ) \n","\n","- Possible Cause :  Not Optimal Implementation or Reshape forward function (status : <font color = 'yellow'> Pending</font>)\n","  - Itertools\n","  - exec()\n","\n","- Built-in reshape function is much faster and performs as expected but the map it provides is wrong. Overall it is faster than original 3d TCL but with a wrong mapping.\n","\n","- Version 2 of chunk reshape (status : <font color = 'red'> Rejected </font>) \n","  - It is faster but not as fast as built-in reshape function and overall still takes longer to run than original 3d TCL.\n","\n","- Version 3 of chunk reshape (status : <font color = 'red'> Rejected </font>)\n","  - It is still faster than version 2 or the original as it generate the output from the reshaped version of input but it still takes longer to run than built-in reshape function"]},{"cell_type":"code","execution_count":132,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10646,"status":"ok","timestamp":1683987248835,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"u-R0qfusHsiE","outputId":"d1c52166-049f-46ac-c511-93aae05f13bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Time spent on first convolution Layer  3.1734468936920166\n","Time spent on second convolution Layer  1.7070107460021973\n","\n","######################################\n","\n","\n","Time spent on Reshaping the Tensor  0.35261011123657227\n","Time spent on TCL 6 Dimensional  0.06156492233276367\n","Time spent on squeeze()  0.0011353492736816406\n","Total Time spent TCL 6 dimensional and squeeze()  0.0630791187286377\n","Total Time spent on Reshape + TCL 6 dimensional +  squeeze()  0.4191412925720215\n","\n","######################################\n","\n","\n","Time spent on TCL 3 Dimensional  0.09839797019958496\n","\n","######################################\n","\n","\n","Reshape time using Tensoly Reshape function :  0.001592397689819336\n","Time spent on TCL 6 Dimensional  0.07184123992919922\n","Total Time spent squeeze()  0.0012443065643310547\n","Total Time spent on Reshape + TCL 6 dimensional +  squeeze() with .reshape function  0.07605361938476562\n","\n","######################################\n","\n","\n","Time spent on Reshaping the Tensor (version2)  0.3576040267944336\n","Time spent on TCL 6 Dimensional (version2)  0.06874752044677734\n","Time spent on squeeze() (version2)  8.821487426757812e-05\n","Total Time spent TCL 6 dimensional and squeeze() (version2)  0.07006669044494629\n","Total Time spent on Reshape + TCL 6 dimensional +  squeeze() (version 2)  0.4294731616973877\n","\n","######################################\n","\n","\n","Time spent on Reshaping the Tensor (version3)  0.29130077362060547\n","Time spent on TCL 6 Dimensional (version3)  0.055571556091308594\n","Time spent on squeeze() (version3)  0.00013327598571777344\n","Total Time spent TCL 6 dimensional and squeeze() (version3)  0.057930707931518555\n","Total Time spent on Reshape + TCL 6 dimensional +  squeeze() (version 3)  0.3525862693786621\n","\n","######################################\n","\n","\n","Time spent on TRL (input rank : [13,2,2])  0.0031533241271972656\n","Time spent on TRL (input rank : [30,2,2])  0.00559687614440918\n"]}],"source":["tempstring = \"\\n######################################\\n\\n\"\n","\n","# Dataset Loaders\n","batch_size, device, train_loader_mnist, test_loader_mnist = MNIST_loader(_batch_size = 15000, _device = 'cuda')\n","\n","\n","# Get a batch from dataset\n","examples_mnist = enumerate(train_loader_mnist)\n","batch_idx, (example_data_mnist, example_targets_mnist) = next(examples_mnist)\n","\n","\n","# One forward through Net\n","conv1 = nn.Conv2d(1, 20, kernel_size=5)\n","st = time.time()\n","x1 = F.relu(F.max_pool2d(conv1(example_data_mnist), 2))\n","elapsed_time = time.time() - st\n","print('Time spent on first convolution Layer ', elapsed_time)\n","\n","\n","conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","st = time.time()\n","x2 = F.relu(F.max_pool2d(conv2(x1), 2))\n","elapsed_time = time.time() - st\n","print('Time spent on second convolution Layer ', elapsed_time)\n","\n","print(tempstring)\n","# For further studies (and for further simplification for viewers)\n","x2_3d = x2\n","x2_reshape = x2\n","x2_version2 = x2\n","x2_version3 = x2\n","\n","\n","# With Reshape\n","Chunk_Reshape = chunkReshape(input_size = [50,4,4], L = [2,2,2], map_type = 1)\n","st = time.time()\n","x3 = Chunk_Reshape(x2)\n","elapsed_time = time.time() - st\n","print('Time spent on Reshaping the Tensor ', elapsed_time)\n","\n","\n","# TCL \n","tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","st_1 = time.time()\n","x4 = F.relu(tcl(x3))\n","elapsed_time_1 = time.time() - st_1\n","print('Time spent on TCL 6 Dimensional ', elapsed_time_1)\n","\n","st_2 = time.time()\n","x5 = x4.squeeze()\n","elapsed_time_2 = time.time() - st_2\n","print('Time spent on squeeze() ', elapsed_time_2)\n","\n","elapsed_time = time.time() - st_1\n","print('Total Time spent TCL 6 dimensional and squeeze() ', elapsed_time)\n","\n","\n","# Total time spent on Reshape + TCL + squeeze()\n","elapsed_time = time.time() - st\n","print('Total Time spent on Reshape + TCL 6 dimensional +  squeeze() ', elapsed_time)\n","\n","print(tempstring)\n","# Case of TCL with 3 dimension\n","\n","tcl_3d = tltorch.TCL(input_shape= [50,4,4], rank=[30,2,2])\n","st = time.time()\n","x4_3d = F.relu(tcl_3d(x2_3d))\n","elapsed_time = time.time() - st\n","print('Time spent on TCL 3 Dimensional ', elapsed_time)\n","\n","print(tempstring)\n","# In case of using reshape in-built function of Tensorly or torch\n","# The result is Not correct but we wish to calculate the time spent\n","st = time.time()\n","x3_reshape = x2_reshape.reshape((batch_size, 2, 2, 2, 25, 2, 2))\n","elapsed_time_1 = time.time() - st\n","print('Reshape time using Tensoly Reshape function : ', elapsed_time_1)\n","st_1 = time.time()\n","x4_reshape = F.relu(tcl(x3_reshape))\n","elapsed_time_2 = time.time() - st_1\n","print('Time spent on TCL 6 Dimensional ', elapsed_time_2)\n","st_2 = time.time()\n","x5_reshape = x4_reshape.squeeze()\n","elapsed_time_3 = time.time() - st_2\n","print('Total Time spent squeeze() ', elapsed_time_3)\n","elapsed_time = time.time() - st\n","print('Total Time spent on Reshape + TCL 6 dimensional +  squeeze() with .reshape function ', elapsed_time)\n","\n","print(tempstring)\n","# In case we are using version 2 of chunk reshape\n","# With Reshape version2\n","Chunk_Reshape = chunkReshape_version2(input_size = [50,4,4], L = [2,2,2], batch_size = batch_size, map_type = 1)\n","st = time.time()\n","x3_version2 = Chunk_Reshape(x2_version2)\n","elapsed_time = time.time() - st\n","print('Time spent on Reshaping the Tensor (version2) ', elapsed_time)\n","\n","\n","# TCL \n","tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","st_1 = time.time()\n","x4_version2 = F.relu(tcl(x3_version2))\n","elapsed_time_1 = time.time() - st_1\n","print('Time spent on TCL 6 Dimensional (version2) ', elapsed_time_1)\n","\n","st_2 = time.time()\n","x5_version2 = x4_version2.squeeze()\n","elapsed_time_2 = time.time() - st_2\n","print('Time spent on squeeze() (version2) ', elapsed_time_2)\n","\n","elapsed_time = time.time() - st_1\n","print('Total Time spent TCL 6 dimensional and squeeze() (version2) ', elapsed_time)\n","\n","\n","# Total time spent on Reshape + TCL + squeeze()\n","elapsed_time = time.time() - st\n","print('Total Time spent on Reshape + TCL 6 dimensional +  squeeze() (version 2) ', elapsed_time)\n","\n","print(tempstring)\n","# In case we are using version 3 of chunk reshape\n","# With Reshape version2\n","Chunk_Reshape = chunkReshape_version3(input_size = [50,4,4], L = [2,2,2], batch_size = batch_size, map_type = 1)\n","st = time.time()\n","x3_version3 = Chunk_Reshape(x2_version3)\n","elapsed_time = time.time() - st\n","print('Time spent on Reshaping the Tensor (version3) ', elapsed_time)\n","\n","\n","# TCL \n","tcl = tltorch.TCL(input_shape= [2,2,2,25,2,2], rank=[1,1,1,13,2,2])\n","st_1 = time.time()\n","x4_version3 = F.relu(tcl(x3_version3))\n","elapsed_time_1 = time.time() - st_1\n","print('Time spent on TCL 6 Dimensional (version3) ', elapsed_time_1)\n","\n","st_2 = time.time()\n","x5_version3 = x4_version3.squeeze()\n","elapsed_time_2 = time.time() - st_2\n","print('Time spent on squeeze() (version3) ', elapsed_time_2)\n","\n","elapsed_time = time.time() - st_1\n","print('Total Time spent TCL 6 dimensional and squeeze() (version3) ', elapsed_time)\n","\n","\n","# Total time spent on Reshape + TCL + squeeze()\n","elapsed_time = time.time() - st\n","print('Total Time spent on Reshape + TCL 6 dimensional +  squeeze() (version 3) ', elapsed_time)\n","\n","print(tempstring)\n","# TRL\n","# TRL input in both cases (with/without reshape) is 3 dimensional \n","# But the ranks are different\n","trl = tltorch.TRL(input_shape = [13,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","st = time.time()\n","x6 = trl(x5)\n","elapsed_time = time.time() - st\n","print('Time spent on TRL (input rank : [13,2,2]) ', elapsed_time)\n","\n","\n","trl_3d = tltorch.TRL(input_shape = [30,2,2] , output_shape = [10], factorization = 'Tucker', rank = [10,3,3,10])\n","st = time.time()\n","x6_3d = trl_3d(x4_3d)\n","elapsed_time = time.time() - st\n","print('Time spent on TRL (input rank : [30,2,2]) ', elapsed_time)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ctSua8cfV8Hl"},"source":[" It is observed that .reshape function performs faster, therefore it is advised to study the base code of .reshape to further improve our Reshape class and forward pass time. \n","\n","\n"," Version 2 still takes longer to execute than original 3D TCL, therefore it has been rejected.  "]},{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683984287992,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"tIrwbzuFSNOR"},"outputs":[],"source":["# torch.as_stride\n","# torch.index_select\n","\n","\n","# tensor = torch.Tensor(np.arange(0,100).reshape(10,10))\n","# temp1 = torch.index_select(tensor,1, torch.tensor(range(0,5)))\n","# torch.index_select(temp1, 0, torch.tensor(range(0,5)))"]},{"cell_type":"code","execution_count":126,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":135},"executionInfo":{"elapsed":8,"status":"error","timestamp":1683986846192,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"},"user_tz":-210},"id":"kBiXDMvuHReb","outputId":"6531aff5-0ab1-4f2b-8846-1a116a6f0f06"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-126-c9e013f4a11f>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    temp1[0,0,0,0] = tensor[5,5])\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"]}],"source":["#import tensorflow as tf\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L5jhFBDxEnOG"},"outputs":[],"source":["tensor = torch.Tensor(np.arange(0,100).reshape(10,10))\n","tensor.reshape(2,2,5,5)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Y2FNS7AedCzs","BuBPtXZn97kA","gB55xpU8LJzQ","DtQ8p0zwaep7","8Ty910HUSR_x","CvcEY6IiVHOT","A93XlVjHhtJ-","A7xE9gL1xdhE"],"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}
